{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hollow-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import paddle.fluid.dygraph as D\n",
    "from paddle import fluid\n",
    "from mindspore.common.tensor import Tensor\n",
    "input_dir='./'\n",
    "output_dir='./c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ruled-string",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.17.5)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.11.0)\n",
      "Requirement already satisfied: sklearn==0.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.8 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.1.8)\n",
      "Collecting paddlepaddle==1.8.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/93/49fff8c63732b618563237ed176b6567c325f2317bd2f56b44d3cb39b5b1/paddlepaddle-1.8.2-cp37-cp37m-manylinux1_x86_64.whl (111.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 111.2 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.7/site-packages (from paddlepaddle==1.8.2->-r requirements.txt (line 2)) (2.24.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from paddlepaddle==1.8.2->-r requirements.txt (line 2)) (3.3.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from paddlepaddle==1.8.2->-r requirements.txt (line 2)) (8.1.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from paddlepaddle==1.8.2->-r requirements.txt (line 2)) (4.4.2)\n",
      "Requirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from paddlepaddle==1.8.2->-r requirements.txt (line 2)) (3.14.0)\n",
      "Collecting pyzmq==18.0.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f7/43/ac5473e08294fd1fc512e54c39b702de1c848391f9b2d073279f5dc7a986/pyzmq-18.0.2-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 999 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn==0.0->-r requirements.txt (line 6)) (0.24.1)\n",
      "Collecting gast>=0.3.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.20.0->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (3.0.4)\n",
      "Collecting scipy<=1.3.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/7f/b535ec711cbcc3246abea4385d17e1b325d4c3404dd86f15fc4f3dba1dbb/scipy-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.2 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting funcsigs\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl (17 kB)\n",
      "Collecting graphviz\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/86/86/89ba50ba65928001d3161f23bfa03945ed18ea13a1d1d44a772ff1fa4e7a/graphviz-0.16-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (0.10.0)\n",
      "Collecting nltk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 145 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (4.51.0)\n",
      "Collecting click\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 6.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting objgraph\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a9/79/9f47706447b9ba0003c0680da4fed1d502adf410e1d953b4d1a5d3486640/objgraph-3.5.0-py2.py3-none-any.whl (17 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0f/13/192104516c4a3d92dc6b5e106ffcfbf0fe35f3c4faa49650205ff652af72/opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 50.4 MB 137 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathlib\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ac/aa/9b065a76b9af472437a0059f77e8f962fe350438b927cb80184c32f075eb/pathlib-1.0.1.tar.gz (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prettytable\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/d5/52e48f3bcf66f838d411ad85c3ac9550c2451d082623e2d4d4df7411ed5c/prettytable-2.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (0.2.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from prettytable->paddlepaddle==1.8.2->-r requirements.txt (line 2)) (52.0.0.post20210125)\n",
      "Collecting pyyaml\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 94 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting rarfile\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/95/f4/c92fab227c7457e3b76a4096ccb655ded9deac869849cb03afbe55dfdc1e/rarfile-4.0-py3-none-any.whl (28 kB)\n",
      "Collecting regex\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/61/b2/8f281520d9f08d0f6771b8160a87a4b487850cde9f1abe257da4d8bab599/regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
      "\u001b[K     |████████████████████████████████| 719 kB 168 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn==0.0->-r requirements.txt (line 6)) (2.1.0)\n",
      "Building wheels for collected packages: nltk, pathlib\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434674 sha256=583911b7f7622a6e198d21b53572494802df374b4ac244f2cf7c726f4ab191da\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jdz2p8pn/wheels/a4/11/6d/2a069739a9961b3127c91a6d792fe8af6f53d93cfc1f234f60\n",
      "  Building wheel for pathlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathlib: filename=pathlib-1.0.1-py3-none-any.whl size=14348 sha256=95724ef73f9aaebbaed4e2ce505fb724b1fc59fa70a0a89ba318ba7fc2b85ce5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jdz2p8pn/wheels/a7/af/d3/4d1de84a05b50616c1b2943a306b98582410e7abdfddba63ee\n",
      "Successfully built nltk pathlib\n",
      "Installing collected packages: scipy, regex, graphviz, click, rarfile, pyyaml, prettytable, pathlib, opencv-python, objgraph, nltk, gast, funcsigs, astor, pyzmq, paddlepaddle\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.0\n",
      "    Uninstalling scipy-1.6.0:\n",
      "      Successfully uninstalled scipy-1.6.0\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 20.0.0\n",
      "    Uninstalling pyzmq-20.0.0:\n",
      "      Successfully uninstalled pyzmq-20.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "determined 0.13.13 requires pyzmq>=18.1.0, but you have pyzmq 18.0.2 which is incompatible.\n",
      "mindspore-gpu 1.1.0 requires scipy>=1.5.3, but you have scipy 1.3.1 which is incompatible.\u001b[0m\n",
      "Successfully installed astor-0.8.1 click-7.1.2 funcsigs-1.0.2 gast-0.4.0 graphviz-0.16 nltk-3.5 objgraph-3.5.0 opencv-python-4.5.1.48 paddlepaddle-1.8.2 pathlib-1.0.1 prettytable-2.0.0 pyyaml-5.4.1 pyzmq-18.0.2 rarfile-4.0 regex-2020.11.13 scipy-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "technological-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_params_map(attention_num=12):\n",
    "    \"\"\"\n",
    "    build params map from paddle-paddle's ERNIE to transformer's BERT\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    weight_map = collections.OrderedDict({\n",
    "        'word_emb.weight': \"bert.bert.bert_embedding_lookup.embedding_table\",\n",
    "        'pos_emb.weight': \"bert.bert.bert_embedding_postprocessor.full_position_embedding.embedding_table\",\n",
    "        'sent_emb.weight': \"bert.bert.bert_embedding_postprocessor.token_type_embedding.embedding_table\",\n",
    "        'ln.weight': 'bert.bert.bert_embedding_postprocessor.layernorm.gamma',\n",
    "        'ln.bias': 'bert.bert.bert_embedding_postprocessor.layernorm.beta',\n",
    "    })\n",
    "    # add attention layers\n",
    "    for i in range(attention_num):\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.q.weight'] = f'bert.bert.bert_encoder.layers.{i}.attention.query_layer.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.q.bias'] = f'bert.bert.bert_encoder.layers.{i}.attention.query_layer.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.k.weight'] = f'bert.bert.bert_encoder.layers.{i}.attention.key_layer.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.k.bias'] = f'bert.bert.bert_encoder.layers.{i}.attention.key_layer.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.v.weight'] = f'bert.bert.bert_encoder.layers.{i}.attention.value_layer.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.v.bias'] = f'bert.bert.bert_encoder.layers.{i}.attention.value_layer.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.o.weight'] = f'bert.bert.bert_encoder.layers.{i}.attention.output.dense.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.attn.o.bias'] = f'bert.bert.bert_encoder.layers.{i}.attention.output.dense.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.ln1.weight'] = f'bert.bert.bert_encoder.layers.{i}.attention.output.layernorm.gamma'\n",
    "        weight_map[f'encoder_stack.block.{i}.ln1.bias'] = f'bert.bert.bert_encoder.layers.{i}.attention.output.layernorm.beta'\n",
    "        weight_map[f'encoder_stack.block.{i}.ffn.i.weight'] = f'bert.bert.bert_encoder.layers.{i}.intermediate.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.ffn.i.bias'] = f'bert.bert.bert_encoder.layers.{i}.intermediate.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.ffn.o.weight'] = f'bert.bert.bert_encoder.layers.{i}.output.dense.weight'\n",
    "        weight_map[f'encoder_stack.block.{i}.ffn.o.bias'] = f'bert.bert.bert_encoder.layers.{i}.output.dense.bias'\n",
    "        weight_map[f'encoder_stack.block.{i}.ln2.weight'] = f'bert.bert.bert_encoder.layers.{i}.output.layernorm.gamma'\n",
    "        weight_map[f'encoder_stack.block.{i}.ln2.bias'] = f'bert.bert.bert_encoder.layers.{i}.output.layernorm.beta'\n",
    "    # add pooler\n",
    "    weight_map.update(\n",
    "        {\n",
    "            'pooler.weight': 'bert.pooler.dense.weight',\n",
    "            'pooler.bias': 'bert.pooler.dense.bias',\n",
    "            'mlm.weight': 'cls.predictions.transform.dense.weight',\n",
    "            'mlm.bias': 'cls.predictions.transform.dense.bias',\n",
    "            'mlm_ln.weight': 'cls.predictions.transform.LayerNorm.gamma',\n",
    "            'mlm_ln.bias': 'cls.predictions.transform.LayerNorm.beta',\n",
    "            'mlm_bias': 'cls.predictions.bias'\n",
    "        }\n",
    "    )\n",
    "    return weight_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hired-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================save config file====================\n",
      "====================save vocab file====================\n",
      "====================extract weights====================\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "print('=' * 20 + 'save config file' + '=' * 20)\n",
    "config = json.load(open(os.path.join(input_dir, 'ernie_config.json'), 'rt', encoding='utf-8'))\n",
    "config['layer_norm_eps'] = 1e-5\n",
    "if 'sent_type_vocab_size' in config:\n",
    "    config['type_vocab_size'] = config['sent_type_vocab_size']\n",
    "config['intermediate_size'] = 4 * config['hidden_size']\n",
    "json.dump(config, open(os.path.join(output_dir, 'config.json'), 'wt', encoding='utf-8'), indent=4)\n",
    "print('=' * 20 + 'save vocab file' + '=' * 20)\n",
    "shutil.copyfile(os.path.join(input_dir, 'vocab.txt'), os.path.join(output_dir, 'vocab.txt'))\n",
    "print('=' * 20 + 'extract weights' + '=' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quarterly-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlm_bias -> cls.predictions.bias (18000,)\n",
      "ln.weight -> bert.bert.bert_embedding_postprocessor.layernorm.gamma (768,)\n",
      "ln.bias -> bert.bert.bert_embedding_postprocessor.layernorm.beta (768,)\n",
      "word_emb.weight -> bert.bert.bert_embedding_lookup.embedding_table (18000, 768)\n",
      "pos_emb.weight -> bert.bert.bert_embedding_postprocessor.full_position_embedding.embedding_table (513, 768)\n",
      "sent_emb.weight -> bert.bert.bert_embedding_postprocessor.token_type_embedding.embedding_table (2, 768)\n",
      "encoder_stack.block.0.attn.q.weight -> bert.bert.bert_encoder.layers.0.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.0.attn.q.bias -> bert.bert.bert_encoder.layers.0.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.0.attn.k.weight -> bert.bert.bert_encoder.layers.0.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.0.attn.k.bias -> bert.bert.bert_encoder.layers.0.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.0.attn.v.weight -> bert.bert.bert_encoder.layers.0.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.0.attn.v.bias -> bert.bert.bert_encoder.layers.0.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.0.attn.o.weight -> bert.bert.bert_encoder.layers.0.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.0.attn.o.bias -> bert.bert.bert_encoder.layers.0.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.0.ln1.weight -> bert.bert.bert_encoder.layers.0.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.0.ln1.bias -> bert.bert.bert_encoder.layers.0.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.0.ffn.i.weight -> bert.bert.bert_encoder.layers.0.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.0.ffn.i.bias -> bert.bert.bert_encoder.layers.0.intermediate.bias (3072,)\n",
      "encoder_stack.block.0.ffn.o.weight -> bert.bert.bert_encoder.layers.0.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.0.ffn.o.bias -> bert.bert.bert_encoder.layers.0.output.dense.bias (768,)\n",
      "encoder_stack.block.0.ln2.weight -> bert.bert.bert_encoder.layers.0.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.0.ln2.bias -> bert.bert.bert_encoder.layers.0.output.layernorm.beta (768,)\n",
      "encoder_stack.block.1.attn.q.weight -> bert.bert.bert_encoder.layers.1.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.1.attn.q.bias -> bert.bert.bert_encoder.layers.1.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.1.attn.k.weight -> bert.bert.bert_encoder.layers.1.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.1.attn.k.bias -> bert.bert.bert_encoder.layers.1.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.1.attn.v.weight -> bert.bert.bert_encoder.layers.1.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.1.attn.v.bias -> bert.bert.bert_encoder.layers.1.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.1.attn.o.weight -> bert.bert.bert_encoder.layers.1.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.1.attn.o.bias -> bert.bert.bert_encoder.layers.1.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.1.ln1.weight -> bert.bert.bert_encoder.layers.1.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.1.ln1.bias -> bert.bert.bert_encoder.layers.1.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.1.ffn.i.weight -> bert.bert.bert_encoder.layers.1.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.1.ffn.i.bias -> bert.bert.bert_encoder.layers.1.intermediate.bias (3072,)\n",
      "encoder_stack.block.1.ffn.o.weight -> bert.bert.bert_encoder.layers.1.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.1.ffn.o.bias -> bert.bert.bert_encoder.layers.1.output.dense.bias (768,)\n",
      "encoder_stack.block.1.ln2.weight -> bert.bert.bert_encoder.layers.1.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.1.ln2.bias -> bert.bert.bert_encoder.layers.1.output.layernorm.beta (768,)\n",
      "encoder_stack.block.2.attn.q.weight -> bert.bert.bert_encoder.layers.2.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.2.attn.q.bias -> bert.bert.bert_encoder.layers.2.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.2.attn.k.weight -> bert.bert.bert_encoder.layers.2.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.2.attn.k.bias -> bert.bert.bert_encoder.layers.2.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.2.attn.v.weight -> bert.bert.bert_encoder.layers.2.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.2.attn.v.bias -> bert.bert.bert_encoder.layers.2.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.2.attn.o.weight -> bert.bert.bert_encoder.layers.2.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.2.attn.o.bias -> bert.bert.bert_encoder.layers.2.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.2.ln1.weight -> bert.bert.bert_encoder.layers.2.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.2.ln1.bias -> bert.bert.bert_encoder.layers.2.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.2.ffn.i.weight -> bert.bert.bert_encoder.layers.2.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.2.ffn.i.bias -> bert.bert.bert_encoder.layers.2.intermediate.bias (3072,)\n",
      "encoder_stack.block.2.ffn.o.weight -> bert.bert.bert_encoder.layers.2.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.2.ffn.o.bias -> bert.bert.bert_encoder.layers.2.output.dense.bias (768,)\n",
      "encoder_stack.block.2.ln2.weight -> bert.bert.bert_encoder.layers.2.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.2.ln2.bias -> bert.bert.bert_encoder.layers.2.output.layernorm.beta (768,)\n",
      "encoder_stack.block.3.attn.q.weight -> bert.bert.bert_encoder.layers.3.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.3.attn.q.bias -> bert.bert.bert_encoder.layers.3.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.3.attn.k.weight -> bert.bert.bert_encoder.layers.3.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.3.attn.k.bias -> bert.bert.bert_encoder.layers.3.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.3.attn.v.weight -> bert.bert.bert_encoder.layers.3.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.3.attn.v.bias -> bert.bert.bert_encoder.layers.3.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.3.attn.o.weight -> bert.bert.bert_encoder.layers.3.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.3.attn.o.bias -> bert.bert.bert_encoder.layers.3.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.3.ln1.weight -> bert.bert.bert_encoder.layers.3.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.3.ln1.bias -> bert.bert.bert_encoder.layers.3.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.3.ffn.i.weight -> bert.bert.bert_encoder.layers.3.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.3.ffn.i.bias -> bert.bert.bert_encoder.layers.3.intermediate.bias (3072,)\n",
      "encoder_stack.block.3.ffn.o.weight -> bert.bert.bert_encoder.layers.3.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.3.ffn.o.bias -> bert.bert.bert_encoder.layers.3.output.dense.bias (768,)\n",
      "encoder_stack.block.3.ln2.weight -> bert.bert.bert_encoder.layers.3.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.3.ln2.bias -> bert.bert.bert_encoder.layers.3.output.layernorm.beta (768,)\n",
      "encoder_stack.block.4.attn.q.weight -> bert.bert.bert_encoder.layers.4.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.4.attn.q.bias -> bert.bert.bert_encoder.layers.4.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.4.attn.k.weight -> bert.bert.bert_encoder.layers.4.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.4.attn.k.bias -> bert.bert.bert_encoder.layers.4.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.4.attn.v.weight -> bert.bert.bert_encoder.layers.4.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.4.attn.v.bias -> bert.bert.bert_encoder.layers.4.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.4.attn.o.weight -> bert.bert.bert_encoder.layers.4.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.4.attn.o.bias -> bert.bert.bert_encoder.layers.4.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.4.ln1.weight -> bert.bert.bert_encoder.layers.4.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.4.ln1.bias -> bert.bert.bert_encoder.layers.4.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.4.ffn.i.weight -> bert.bert.bert_encoder.layers.4.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.4.ffn.i.bias -> bert.bert.bert_encoder.layers.4.intermediate.bias (3072,)\n",
      "encoder_stack.block.4.ffn.o.weight -> bert.bert.bert_encoder.layers.4.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.4.ffn.o.bias -> bert.bert.bert_encoder.layers.4.output.dense.bias (768,)\n",
      "encoder_stack.block.4.ln2.weight -> bert.bert.bert_encoder.layers.4.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.4.ln2.bias -> bert.bert.bert_encoder.layers.4.output.layernorm.beta (768,)\n",
      "encoder_stack.block.5.attn.q.weight -> bert.bert.bert_encoder.layers.5.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.5.attn.q.bias -> bert.bert.bert_encoder.layers.5.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.5.attn.k.weight -> bert.bert.bert_encoder.layers.5.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.5.attn.k.bias -> bert.bert.bert_encoder.layers.5.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.5.attn.v.weight -> bert.bert.bert_encoder.layers.5.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.5.attn.v.bias -> bert.bert.bert_encoder.layers.5.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.5.attn.o.weight -> bert.bert.bert_encoder.layers.5.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.5.attn.o.bias -> bert.bert.bert_encoder.layers.5.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.5.ln1.weight -> bert.bert.bert_encoder.layers.5.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.5.ln1.bias -> bert.bert.bert_encoder.layers.5.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.5.ffn.i.weight -> bert.bert.bert_encoder.layers.5.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.5.ffn.i.bias -> bert.bert.bert_encoder.layers.5.intermediate.bias (3072,)\n",
      "encoder_stack.block.5.ffn.o.weight -> bert.bert.bert_encoder.layers.5.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.5.ffn.o.bias -> bert.bert.bert_encoder.layers.5.output.dense.bias (768,)\n",
      "encoder_stack.block.5.ln2.weight -> bert.bert.bert_encoder.layers.5.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.5.ln2.bias -> bert.bert.bert_encoder.layers.5.output.layernorm.beta (768,)\n",
      "encoder_stack.block.6.attn.q.weight -> bert.bert.bert_encoder.layers.6.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.6.attn.q.bias -> bert.bert.bert_encoder.layers.6.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.6.attn.k.weight -> bert.bert.bert_encoder.layers.6.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.6.attn.k.bias -> bert.bert.bert_encoder.layers.6.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.6.attn.v.weight -> bert.bert.bert_encoder.layers.6.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.6.attn.v.bias -> bert.bert.bert_encoder.layers.6.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.6.attn.o.weight -> bert.bert.bert_encoder.layers.6.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.6.attn.o.bias -> bert.bert.bert_encoder.layers.6.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.6.ln1.weight -> bert.bert.bert_encoder.layers.6.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.6.ln1.bias -> bert.bert.bert_encoder.layers.6.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.6.ffn.i.weight -> bert.bert.bert_encoder.layers.6.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.6.ffn.i.bias -> bert.bert.bert_encoder.layers.6.intermediate.bias (3072,)\n",
      "encoder_stack.block.6.ffn.o.weight -> bert.bert.bert_encoder.layers.6.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.6.ffn.o.bias -> bert.bert.bert_encoder.layers.6.output.dense.bias (768,)\n",
      "encoder_stack.block.6.ln2.weight -> bert.bert.bert_encoder.layers.6.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.6.ln2.bias -> bert.bert.bert_encoder.layers.6.output.layernorm.beta (768,)\n",
      "encoder_stack.block.7.attn.q.weight -> bert.bert.bert_encoder.layers.7.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.7.attn.q.bias -> bert.bert.bert_encoder.layers.7.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.7.attn.k.weight -> bert.bert.bert_encoder.layers.7.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.7.attn.k.bias -> bert.bert.bert_encoder.layers.7.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.7.attn.v.weight -> bert.bert.bert_encoder.layers.7.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.7.attn.v.bias -> bert.bert.bert_encoder.layers.7.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.7.attn.o.weight -> bert.bert.bert_encoder.layers.7.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.7.attn.o.bias -> bert.bert.bert_encoder.layers.7.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.7.ln1.weight -> bert.bert.bert_encoder.layers.7.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.7.ln1.bias -> bert.bert.bert_encoder.layers.7.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.7.ffn.i.weight -> bert.bert.bert_encoder.layers.7.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.7.ffn.i.bias -> bert.bert.bert_encoder.layers.7.intermediate.bias (3072,)\n",
      "encoder_stack.block.7.ffn.o.weight -> bert.bert.bert_encoder.layers.7.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.7.ffn.o.bias -> bert.bert.bert_encoder.layers.7.output.dense.bias (768,)\n",
      "encoder_stack.block.7.ln2.weight -> bert.bert.bert_encoder.layers.7.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.7.ln2.bias -> bert.bert.bert_encoder.layers.7.output.layernorm.beta (768,)\n",
      "encoder_stack.block.8.attn.q.weight -> bert.bert.bert_encoder.layers.8.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.8.attn.q.bias -> bert.bert.bert_encoder.layers.8.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.8.attn.k.weight -> bert.bert.bert_encoder.layers.8.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.8.attn.k.bias -> bert.bert.bert_encoder.layers.8.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.8.attn.v.weight -> bert.bert.bert_encoder.layers.8.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.8.attn.v.bias -> bert.bert.bert_encoder.layers.8.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.8.attn.o.weight -> bert.bert.bert_encoder.layers.8.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.8.attn.o.bias -> bert.bert.bert_encoder.layers.8.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.8.ln1.weight -> bert.bert.bert_encoder.layers.8.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.8.ln1.bias -> bert.bert.bert_encoder.layers.8.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.8.ffn.i.weight -> bert.bert.bert_encoder.layers.8.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.8.ffn.i.bias -> bert.bert.bert_encoder.layers.8.intermediate.bias (3072,)\n",
      "encoder_stack.block.8.ffn.o.weight -> bert.bert.bert_encoder.layers.8.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.8.ffn.o.bias -> bert.bert.bert_encoder.layers.8.output.dense.bias (768,)\n",
      "encoder_stack.block.8.ln2.weight -> bert.bert.bert_encoder.layers.8.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.8.ln2.bias -> bert.bert.bert_encoder.layers.8.output.layernorm.beta (768,)\n",
      "encoder_stack.block.9.attn.q.weight -> bert.bert.bert_encoder.layers.9.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.9.attn.q.bias -> bert.bert.bert_encoder.layers.9.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.9.attn.k.weight -> bert.bert.bert_encoder.layers.9.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.9.attn.k.bias -> bert.bert.bert_encoder.layers.9.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.9.attn.v.weight -> bert.bert.bert_encoder.layers.9.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.9.attn.v.bias -> bert.bert.bert_encoder.layers.9.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.9.attn.o.weight -> bert.bert.bert_encoder.layers.9.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.9.attn.o.bias -> bert.bert.bert_encoder.layers.9.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.9.ln1.weight -> bert.bert.bert_encoder.layers.9.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.9.ln1.bias -> bert.bert.bert_encoder.layers.9.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.9.ffn.i.weight -> bert.bert.bert_encoder.layers.9.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.9.ffn.i.bias -> bert.bert.bert_encoder.layers.9.intermediate.bias (3072,)\n",
      "encoder_stack.block.9.ffn.o.weight -> bert.bert.bert_encoder.layers.9.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.9.ffn.o.bias -> bert.bert.bert_encoder.layers.9.output.dense.bias (768,)\n",
      "encoder_stack.block.9.ln2.weight -> bert.bert.bert_encoder.layers.9.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.9.ln2.bias -> bert.bert.bert_encoder.layers.9.output.layernorm.beta (768,)\n",
      "encoder_stack.block.10.attn.q.weight -> bert.bert.bert_encoder.layers.10.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.10.attn.q.bias -> bert.bert.bert_encoder.layers.10.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.10.attn.k.weight -> bert.bert.bert_encoder.layers.10.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.10.attn.k.bias -> bert.bert.bert_encoder.layers.10.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.10.attn.v.weight -> bert.bert.bert_encoder.layers.10.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.10.attn.v.bias -> bert.bert.bert_encoder.layers.10.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.10.attn.o.weight -> bert.bert.bert_encoder.layers.10.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.10.attn.o.bias -> bert.bert.bert_encoder.layers.10.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.10.ln1.weight -> bert.bert.bert_encoder.layers.10.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.10.ln1.bias -> bert.bert.bert_encoder.layers.10.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.10.ffn.i.weight -> bert.bert.bert_encoder.layers.10.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.10.ffn.i.bias -> bert.bert.bert_encoder.layers.10.intermediate.bias (3072,)\n",
      "encoder_stack.block.10.ffn.o.weight -> bert.bert.bert_encoder.layers.10.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.10.ffn.o.bias -> bert.bert.bert_encoder.layers.10.output.dense.bias (768,)\n",
      "encoder_stack.block.10.ln2.weight -> bert.bert.bert_encoder.layers.10.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.10.ln2.bias -> bert.bert.bert_encoder.layers.10.output.layernorm.beta (768,)\n",
      "encoder_stack.block.11.attn.q.weight -> bert.bert.bert_encoder.layers.11.attention.query_layer.weight (768, 768)\n",
      "encoder_stack.block.11.attn.q.bias -> bert.bert.bert_encoder.layers.11.attention.query_layer.bias (768,)\n",
      "encoder_stack.block.11.attn.k.weight -> bert.bert.bert_encoder.layers.11.attention.key_layer.weight (768, 768)\n",
      "encoder_stack.block.11.attn.k.bias -> bert.bert.bert_encoder.layers.11.attention.key_layer.bias (768,)\n",
      "encoder_stack.block.11.attn.v.weight -> bert.bert.bert_encoder.layers.11.attention.value_layer.weight (768, 768)\n",
      "encoder_stack.block.11.attn.v.bias -> bert.bert.bert_encoder.layers.11.attention.value_layer.bias (768,)\n",
      "encoder_stack.block.11.attn.o.weight -> bert.bert.bert_encoder.layers.11.attention.output.dense.weight (768, 768)\n",
      "encoder_stack.block.11.attn.o.bias -> bert.bert.bert_encoder.layers.11.attention.output.dense.bias (768,)\n",
      "encoder_stack.block.11.ln1.weight -> bert.bert.bert_encoder.layers.11.attention.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.11.ln1.bias -> bert.bert.bert_encoder.layers.11.attention.output.layernorm.beta (768,)\n",
      "encoder_stack.block.11.ffn.i.weight -> bert.bert.bert_encoder.layers.11.intermediate.weight (3072, 768)\n",
      "encoder_stack.block.11.ffn.i.bias -> bert.bert.bert_encoder.layers.11.intermediate.bias (3072,)\n",
      "encoder_stack.block.11.ffn.o.weight -> bert.bert.bert_encoder.layers.11.output.dense.weight (768, 3072)\n",
      "encoder_stack.block.11.ffn.o.bias -> bert.bert.bert_encoder.layers.11.output.dense.bias (768,)\n",
      "encoder_stack.block.11.ln2.weight -> bert.bert.bert_encoder.layers.11.output.layernorm.gamma (768,)\n",
      "encoder_stack.block.11.ln2.bias -> bert.bert.bert_encoder.layers.11.output.layernorm.beta (768,)\n",
      "pooler.weight -> bert.pooler.dense.weight (768, 768)\n",
      "pooler.bias -> bert.pooler.dense.bias (768,)\n",
      "mlm.weight -> cls.predictions.transform.dense.weight (768, 768)\n",
      "mlm.bias -> cls.predictions.transform.dense.bias (768,)\n",
      "mlm_ln.weight -> cls.predictions.transform.LayerNorm.gamma (768,)\n",
      "mlm_ln.bias -> cls.predictions.transform.LayerNorm.beta (768,)\n"
     ]
    }
   ],
   "source": [
    "state_dict = []\n",
    "weight_map = build_params_map(attention_num=config['num_hidden_layers'])\n",
    "with fluid.dygraph.guard():\n",
    "    paddle_paddle_params, _ = D.load_dygraph(os.path.join(input_dir, 'saved_weights'))\n",
    "for weight_name, weight_value in paddle_paddle_params.items():\n",
    "    if 'weight' in weight_name:\n",
    "        if 'encoder_stack' in weight_name or 'pooler' in weight_name or 'mlm.' in weight_name:\n",
    "            weight_value = weight_value.transpose()\n",
    "    state_dict.append({'name':weight_map[weight_name],'data':Tensor(weight_value)})\n",
    "    print(weight_name, '->', weight_map[weight_name], weight_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "digital-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train.serialization import save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "indie-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(state_dict,'2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-position",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
